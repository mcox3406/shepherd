"""
Visualize detailed results from ShEPhERD inference scaling experiments.

Reads the 'all_molecules_log.csv' file generated by run_inference_scaling_experiment.py
and produces plots analyzing score distributions, progress over time, property trade-offs,
and chemical diversity.
"""

import os
import sys
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import logging

from rdkit import Chem, DataStructs
from rdkit.Chem import AllChem


from shepherd.inference_scaling.utils import create_rdkit_molecule

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['figure.dpi'] = 100


def parse_xyz_content(xyz_content):
    """Parse XYZ file content into atoms and positions lists."""
    lines = xyz_content.strip().split('\n')
    if len(lines) < 3:
        logging.warning("XYZ content has too few lines.")
        return None, None
        
    try:
        num_atoms = int(lines[0].strip())
        if len(lines) < num_atoms + 2:
             logging.warning(f"XYZ header says {num_atoms} atoms, but only {len(lines)-2} coordinate lines found.")
             num_atoms = len(lines) - 2 

        atoms = []
        positions = []
        pt = Chem.GetPeriodicTable()
        max_atomic_num = 118 
        element_map = {pt.GetElementSymbol(i).lower(): i for i in range(1, max_atomic_num + 1)}

        for i in range(2, num_atoms + 2):
            parts = lines[i].split()
            if len(parts) < 4:
                logging.warning(f"Skipping malformed line in XYZ: {lines[i]}")
                continue
            symbol = parts[0]
            atomic_num = element_map.get(symbol.lower()) # use the map, lookup lowercase symbol
            if atomic_num is None:
                 logging.warning(f"Unknown element symbol '{symbol}' in XYZ line: {lines[i]}. Skipping atom.")
                 continue # skip atoms with unknown symbols
            
            atoms.append(atomic_num)
            pos = [float(parts[j]) for j in range(1, 4)]
            positions.append(pos)
            
        return np.array(atoms), np.array(positions)
    except Exception as e:
        logging.error(f"Error parsing XYZ content: {e}")
        return None, None

def load_data(experiment_dir):
    """load the all_molecules_log.csv file."""
    log_file = experiment_dir / "all_molecules_log.csv"
    if not log_file.exists():
        logging.error(f"Log file not found: {log_file}")
        return None
    
    try:
        df = pd.read_csv(log_file)
        # add a cumulative evaluation counter
        df['evaluation'] = range(1, len(df) + 1)
        logging.info(f"Loaded {len(df)} records from {log_file}")
        return df
    except Exception as e:
        logging.error(f"Error loading data from {log_file}: {e}")
        return None

def create_output_dir(experiment_dir):
    """Create the analysis output directory."""
    output_dir = experiment_dir / "analysis"
    output_dir.mkdir(exist_ok=True)
    logging.info(f"Saving analysis results to: {output_dir}")
    return output_dir

def plot_score_distributions(df, output_dir):
    """Plot histograms of SA, cLogP, QED, and combined scores."""
    logging.info("Plotting score distributions...")
    fig, axes = plt.subplots(1, 4, figsize=(20, 5))
    
    sns.histplot(df['sa_score'], kde=True, ax=axes[0], bins=20)
    axes[0].set_title('SA Score Distribution')
    axes[0].set_xlabel('SA Score')
    
    sns.histplot(df['clogp_score'], kde=True, ax=axes[1], bins=20)
    axes[1].set_title('cLogP Score Distribution')
    axes[1].set_xlabel('cLogP Score')
    
    sns.histplot(df['qed_score'], kde=True, ax=axes[2], bins=20)
    axes[2].set_title('QED Score Distribution')
    axes[2].set_xlabel('QED Score')
    
    sns.histplot(df['combined_score'], kde=True, ax=axes[3], bins=20)
    axes[3].set_title('Combined Score Distribution')
    axes[3].set_xlabel('Combined Score')
    
    plt.tight_layout()
    plot_path = output_dir / "score_distributions.png"
    plt.savefig(plot_path)
    plt.close(fig)
    logging.info(f"Saved score distributions plot to {plot_path}")

def plot_score_vs_evaluation(df, output_dir):
    """Plot combined score vs. evaluation number and score distribution."""
    logging.info("Plotting score vs. evaluation and distribution...")

    fig, axes = plt.subplots(2, 1, figsize=(10, 10), sharex=False) # sharex=False as x-axes are different
    
    # scatter plot of score vs. evaluation
    ax1 = axes[0]
    ax1.scatter(df['evaluation'], df['combined_score'], alpha=0.5, s=10) 
    
    # highlight best score found
    best_idx = df['combined_score'].idxmax()
    ax1.scatter(df.loc[best_idx, 'evaluation'], df.loc[best_idx, 'combined_score'], 
               color='r', marker='*', s=200, label=f"Best: {df.loc[best_idx, 'combined_score']:.4f}")
               
    ax1.set_title('Combined Score vs. Evaluation Number')
    ax1.set_ylabel('Combined Score')
    ax1.legend()
    ax1.grid(True)

    # histogram of combined scores
    ax2 = axes[1]
    sns.histplot(df['combined_score'], kde=True, ax=ax2, bins=30)
    ax2.set_title('Distribution of Combined Scores')
    ax2.set_xlabel('Combined Score')
    ax2.set_ylabel('Frequency')

    plt.tight_layout()
    
    plot_path = output_dir / "score_vs_evaluation_and_distribution.png"
    plt.savefig(plot_path)
    plt.close(fig)
    logging.info(f"Saved score vs. evaluation plot to {plot_path}")

def plot_sa_vs_clogp(df, output_dir):
    """Plot SA score vs. cLogP score, colored by combined score."""
    logging.info("Plotting SA score vs. cLogP score...")
    fig, ax = plt.subplots()
    
    scatter = ax.scatter(df['sa_score'], df['clogp_score'], c=df['combined_score'], 
                         cmap='viridis', alpha=0.6, s=15)
                         
    # add colorbar
    cbar = fig.colorbar(scatter)
    cbar.set_label('Combined Score')
    
    ax.set_title('SA Score vs. cLogP Score Trade-off')
    ax.set_xlabel('SA Score')
    ax.set_ylabel('cLogP Score')
    ax.grid(True, alpha=0.3)

    plot_path = output_dir / "sa_vs_clogp.png"
    plt.savefig(plot_path)
    plt.close(fig)
    logging.info(f"Saved SA vs. cLogP plot to {plot_path}")

def plot_qed_relationships(df, output_dir):
    """Plot QED score vs. other properties."""
    logging.info("Plotting QED score relationships...")
    
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    # QED vs SA Score
    scatter1 = axes[0].scatter(df['sa_score'], df['qed_score'], c=df['combined_score'], 
                              cmap='viridis', alpha=0.6, s=15)
    axes[0].set_title('QED Score vs. SA Score')
    axes[0].set_xlabel('SA Score')
    axes[0].set_ylabel('QED Score')
    axes[0].grid(True, alpha=0.3)
    cbar1 = fig.colorbar(scatter1, ax=axes[0])
    cbar1.set_label('Combined Score')
    
    # QED vs cLogP Score
    scatter2 = axes[1].scatter(df['clogp_score'], df['qed_score'], c=df['combined_score'], 
                              cmap='viridis', alpha=0.6, s=15)
    axes[1].set_title('QED Score vs. cLogP Score')
    axes[1].set_xlabel('cLogP Score')
    axes[1].set_ylabel('QED Score')
    axes[1].grid(True, alpha=0.3)
    cbar2 = fig.colorbar(scatter2, ax=axes[1])
    cbar2.set_label('Combined Score')
    
    plt.tight_layout()
    plot_path = output_dir / "qed_relationships.png"
    plt.savefig(plot_path)
    plt.close(fig)
    logging.info(f"Saved QED relationships plot to {plot_path}")

def plot_chemical_diversity(df, output_dir):
    """Calculate and plot pairwise Tanimoto similarity distribution."""
        
    logging.info("Calculating chemical diversity (this may take a while)...")
    
    # use the newly processed SMILES column
    if 'processed_smiles' not in df.columns:
        logging.error("Column 'processed_smiles' not found. Cannot calculate diversity.")
        return
        
    # filter out invalid SMILES (None or other non-string values)
    valid_smiles = df['processed_smiles'][df['processed_smiles'].notna() & 
                                         df['processed_smiles'].apply(lambda x: isinstance(x, str))].tolist()
    
    if len(valid_smiles) < 2:
        logging.warning(f"Not enough valid SMILES found in 'processed_smiles' column ({len(valid_smiles)}) to calculate diversity.")
        return

    logging.info(f"Found {len(valid_smiles)} valid SMILES for diversity calculation.")
    mols = [Chem.MolFromSmiles(s) for s in valid_smiles]
    mols = [m for m in mols if m is not None]

    if len(mols) < 2:
        logging.warning("Not enough valid RDKit molecules created to calculate diversity.")
        return
        
    fps = [AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048) for m in mols]
    similarities = []
    num_fps = len(fps)
    for i in range(num_fps):
        for j in range(i + 1, num_fps):
            sim = DataStructs.TanimotoSimilarity(fps[i], fps[j])
            similarities.append(sim)
            
    if not similarities:
        logging.warning("Could not compute any similarities.")
        return

    fig, ax = plt.subplots()
    sns.histplot(similarities, kde=False, bins=50, ax=ax)
    mean_sim = np.mean(similarities)
    ax.axvline(mean_sim, color='r', linestyle='--', label=f'Mean: {mean_sim:.3f}')
    ax.set_title(f'Pairwise Tanimoto Similarity (Morgan FP, n={len(similarities)})')
    ax.set_xlabel('Tanimoto Similarity')
    ax.set_ylabel('Frequency')
    ax.legend()
    
    plot_path = output_dir / "tanimoto_similarity_distribution.png"
    plt.savefig(plot_path)
    plt.close(fig)
    logging.info(f"Saved Tanimoto similarity plot to {plot_path}")

def rescale_properties(df):
    """
    Rescale normalized property scores back to their original scales for better interpretation.
    
    Args:
        df: DataFrame with normalized property scores
        
    Returns:
        DataFrame with additional columns containing rescaled properties
    """
    df_rescaled = df.copy()
    
    # SA score rescaling (from [0,1] to original [1,10] where 1 is easy, 10 is hard)
    if 'sa_score' in df.columns:
        df_rescaled['sa_score_orig'] = 1 + 9 * (1 - df['sa_score'])
    
    # cLogP rescaling (from [0,1] to original [-1,15] range)
    if 'clogp_score' in df.columns:
        df_rescaled['clogp_orig'] = df['clogp_score'] * 16 - 1  # maps 0->-1, 1->15
    
    # QED is already in [0,1] so no rescaling needed
    
    return df_rescaled

def main():
    parser = argparse.ArgumentParser(description='Visualize detailed ShEPhERD inference scaling results.')
    parser.add_argument('experiment_dir', type=str, 
                        help='Path to the specific experiment results directory (e.g., inference_scaling_experiments/my_experiment_name)')
    args = parser.parse_args()

    experiment_path = Path(args.experiment_dir).resolve()
    
    if not experiment_path.is_dir():
        logging.error(f"Experiment directory not found: {experiment_path}")
        sys.exit(1)

    df = load_data(experiment_path)
    if df is None:
        sys.exit(1)

    # generate RDKit Mols and SMILES from XYZ
    logging.info("Processing XYZ files to generate RDKit molecules and SMILES...")
    processed_smiles = []
    all_mols_dir = experiment_path / "all_molecules"
    
    if not all_mols_dir.is_dir():
            logging.error(f"'all_molecules' directory not found in {experiment_path}. Cannot process XYZ files.")
            df['processed_smiles'] = None # Add column even if processing fails
    else:
        num_processed = 0
        num_success = 0
        # use tqdm for progress bar if available, otherwise simple loop
        try:
            from tqdm import tqdm
            iterator = tqdm(df.itertuples(), total=len(df), desc="Processing XYZ")
        except ImportError:
            iterator = df.itertuples()

        for row in iterator:
            xyz_filename = getattr(row, 'filename', None)
            current_smiles = None # Default to None
            if xyz_filename and isinstance(xyz_filename, str) and xyz_filename != "error_generating_xyz":
                xyz_path = all_mols_dir / xyz_filename
                if xyz_path.exists():
                    try:
                        with open(xyz_path, 'r') as f_xyz:
                            xyz_content = f_xyz.read()
                        
                        atoms, positions = parse_xyz_content(xyz_content)
                        
                        if atoms is not None and positions is not None and len(atoms) > 0:
                            # create minimal sample dict for create_rdkit_molecule
                            mock_sample = {'x1': {'atoms': atoms, 'positions': positions}}
                            # suppress debug messages from create_rdkit_molecule during this potentially long loop
                            logging.getLogger().setLevel(logging.INFO) 
                            mol = create_rdkit_molecule(mock_sample)
                            logging.getLogger().setLevel(logging.INFO) # reset level just in case
                            
                            if mol:
                                current_smiles = Chem.MolToSmiles(mol)
                                num_success += 1
                            # else: create_rdkit_molecule logs the failure reason
                        else:
                            logging.warning(f"Failed to parse content of {xyz_filename}")
                            
                    except Exception as e:
                        logging.error(f"Error reading or processing {xyz_path}: {e}")
                else:
                    logging.warning(f"XYZ file not found: {xyz_path}")
            else:
                logging.debug(f"Skipping row {getattr(row, 'Index', '?')} due to missing or invalid filename: {xyz_filename}")
            
            processed_smiles.append(current_smiles)
            num_processed += 1
            # occasionally update progress if tqdm not available
            if 'iterator' not in locals() and num_processed % 500 == 0:
                logging.info(f"Processed {num_processed}/{len(df)} XYZ files...")

        df['processed_smiles'] = processed_smiles
        logging.info(f"Finished processing XYZ. Successfully generated SMILES for {num_success}/{num_processed} files.")

    # -----------------------------------------------------------------

    output_dir = create_output_dir(experiment_path)

    plot_score_distributions(df, output_dir)
    plot_score_vs_evaluation(df, output_dir)
    plot_sa_vs_clogp(df, output_dir)
    plot_qed_relationships(df, output_dir)
    plot_chemical_diversity(df, output_dir)
    
    logging.info("Visualization script finished.")

if __name__ == "__main__":
    main() 